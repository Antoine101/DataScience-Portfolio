{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Guided Project: Winning Jeopardy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to figure out some patterns in the previous questions of the TV game show Jeopardy that could help us win.\n",
    "\n",
    "Jeopardy is a popular TV show in the US where participants answer questions to win money. It's been running for a few decades, and is a major force in popular culture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, we will work with a dataset of Jeopardy previous questions. The dataset is named `jeopardy.csv`, and contains 20000 rows from the beginning of a full dataset of Jeopardy questions.\n",
    "\n",
    "Let's read this data set in!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "jeopardy = pd.read_csv(\"jeopardy.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by printing the first 5 rows of the dataset to get familiar with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number    Air Date      Round                         Category  Value  \\\n",
       "0         4680  2004-12-31  Jeopardy!                          HISTORY   $200   \n",
       "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   $200   \n",
       "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   $200   \n",
       "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE   $200   \n",
       "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   $200   \n",
       "\n",
       "                                            Question      Answer  \n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  \n",
       "2  The city of Yuma in this state has a record av...     Arizona  \n",
       "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's  \n",
       "4  Signer of the Dec. of Indep., framer of the Co...  John Adams  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And print some info on the dataframe to know more about each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19999 entries, 0 to 19998\n",
      "Data columns (total 7 columns):\n",
      "Show Number    19999 non-null int64\n",
      " Air Date      19999 non-null object\n",
      " Round         19999 non-null object\n",
      " Category      19999 non-null object\n",
      " Value         19999 non-null object\n",
      " Question      19999 non-null object\n",
      " Answer        19999 non-null object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "jeopardy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also print the columns name to ensure their formatting is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Show Number', ' Air Date', ' Round', ' Category', ' Value',\n",
       "       ' Question', ' Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this initial exploration of the data, we can see that:\n",
    "* Column names feature an extra space character in front of them that will need to be stripped out.\n",
    "* The `Air Data` column values are stored as string objects. They will need to be converted to datetime objects.\n",
    "* No column contains any single null value.\n",
    "* The `Value` column values are stored as string objects and will probably need to be converted to numerics to make it more easily to work with them.\n",
    "* Both `Question` and `Answer` columns will likely need to be re-formatted to be usable in our analysis.\n",
    "\n",
    "In the next section, we address some of these cleaning tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning of the Columns Name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by getting rid of the space character that is present in front of the columns name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Show Number', 'Air Date', 'Round', 'Category', 'Value', 'Question',\n",
       "       'Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "jeopardy.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization of the Text Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can start doing analysis on the Jeopardy questions, we need to normalize all of the text columns (the `Question` and `Answer` columns). \n",
    "We are going to lowercase words and remove punctuation so `Don't` and `don't` aren't considered to be different words when we compare them.\n",
    "\n",
    "In the following block of code, we write a function to perform this normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def normalize(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('[^A-Za-z0-9\\s]','',text)\n",
    "    text = re.sub('\\s+',' ',text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then apply this function to the `Question` and `Answer` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    for the last 8 years of his life galileo was u...\n",
      "1    no 2 1912 olympian football star at carlisle i...\n",
      "2    the city of yuma in this state has a record av...\n",
      "Name: clean_question, dtype: object\n",
      "\n",
      "\n",
      "0    copernicus\n",
      "1    jim thorpe\n",
      "2       arizona\n",
      "Name: clean_answer, dtype: object\n"
     ]
    }
   ],
   "source": [
    "jeopardy[\"clean_question\"] = jeopardy[\"Question\"].apply(normalize)\n",
    "jeopardy[\"clean_answer\"] = jeopardy[\"Answer\"].apply(normalize)\n",
    "print(jeopardy[\"clean_question\"].head(3))\n",
    "print('\\n')\n",
    "print(jeopardy[\"clean_answer\"].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization of the `Value` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Value` column should also be numeric, to enable us to manipulate it more easily. We need to remove the dollar sign from the beginning of each value and convert the column from text to numeric type.\n",
    "\n",
    "In the following block of code, we apply the `normalize` function to each item in the `Value` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    200.0\n",
      "1    200.0\n",
      "2    200.0\n",
      "Name: clean_value, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "jeopardy[\"clean_value\"] = jeopardy[\"Value\"].apply(normalize)\n",
    "jeopardy[\"clean_value\"] = pd.to_numeric(jeopardy[\"clean_value\"], errors='coerce', downcast='integer')\n",
    "print(jeopardy[\"clean_value\"].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion of the `Air Date` column to a datetime column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Air Date` column should also be a datetime, not a string, to be able to work with it more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Show Number                int64\n",
       "Air Date          datetime64[ns]\n",
       "Round                     object\n",
       "Category                  object\n",
       "Value                     object\n",
       "Question                  object\n",
       "Answer                    object\n",
       "clean_question            object\n",
       "clean_answer              object\n",
       "clean_value              float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy[\"Air Date\"] = pd.to_datetime(jeopardy[\"Air Date\"])\n",
    "jeopardy.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we performed some cleaning on our data, we can start analysing them. In the next section, we approach different strategies and analyse the past questions and answers to find any useful patterns that could help us for a future win."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which strategy to adopt?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to figure out whether to study past questions, study general knowledge, or not study it all, it would be helpful to figure out two things:\n",
    "\n",
    "* How often the answer is deducible from the question.\n",
    "* How often new questions are repeats of older questions.\n",
    "\n",
    "We can answer the second question by seeing how often complex words (> 6 characters) reoccur. We can answer the first question by seeing how many times words in the answer also occur in the question. We'll work on the first question now, and come back to the second."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How often is the answer deducible from the question?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next block of code, we write a function that takes in a row in `jeopardy` and calculates the percentage of words from the answer that are present in the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_matches(row):\n",
    "    split_answer = row[\"clean_answer\"].split()\n",
    "    split_question = row[\"clean_question\"].split()\n",
    "    \n",
    "    match_count = 0\n",
    "    \n",
    "    if 'the' in split_answer:\n",
    "        split_answer.remove('the')\n",
    "    if len(split_answer) == 0:\n",
    "        return 0\n",
    "    \n",
    "    for word in split_answer:\n",
    "        if word in split_question:\n",
    "            match_count += 1\n",
    "    \n",
    "    return match_count / len(split_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then apply this function to the `jeopardy` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.000000      124\n",
       "0.875000        1\n",
       "0.800000        2\n",
       "0.750000       17\n",
       "0.666667      104\n",
       "0.600000        9\n",
       "0.571429        2\n",
       "0.500000     1448\n",
       "0.444444        1\n",
       "0.428571        2\n",
       "0.400000       26\n",
       "0.350000        1\n",
       "0.333333      494\n",
       "0.300000        2\n",
       "0.285714        7\n",
       "0.250000      155\n",
       "0.200000       68\n",
       "0.181818        2\n",
       "0.166667       27\n",
       "0.142857       21\n",
       "0.125000        9\n",
       "0.111111        2\n",
       "0.000000    17475\n",
       "Name: answer_in_question, dtype: int64"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy[\"answer_in_question\"] = jeopardy.apply(count_matches, axis=1)\n",
    "jeopardy[\"answer_in_question\"].value_counts().sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, most of the rows feature answers that have no words in common with their associated question.\n",
    "On the other side, we have 128 rows where all the words in the answer are present in the question.\n",
    "\n",
    "Let's print one example of each case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  ljubljana bratislava barcelona\n",
      "Answer:  barcelona\n"
     ]
    }
   ],
   "source": [
    "# Example of a case in which all the words in the answer are present in the question\n",
    "print('Question: ',jeopardy[jeopardy[\"answer_in_question\"] == 1].iloc[0][\"clean_question\"])\n",
    "print('Answer: ',jeopardy[jeopardy[\"answer_in_question\"] == 1].iloc[0][\"clean_answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  for the last 8 years of his life galileo was under house arrest for espousing this mans theory\n",
      "Answer:  copernicus\n"
     ]
    }
   ],
   "source": [
    "# Example of a case in which no words from the answer are present in the question\n",
    "print('Question: ',jeopardy[jeopardy[\"answer_in_question\"] == 0].iloc[0][\"clean_question\"])\n",
    "print('Answer: ',jeopardy[jeopardy[\"answer_in_question\"] == 0].iloc[0][\"clean_answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The question in the first case is not really a question but a succession of choices which contains the answer.\n",
    "In the second case, the question is better formulated but it does not indeed contain the answer.\n",
    "\n",
    "Let's now calculate the mean proportion of the new `answer_in_question` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05900196524977763"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy[\"answer_in_question\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that, on average, around 6.3% of an answer's words are present in the question. This is not huge and we can't hope to be able to deduce the answer from the question.\n",
    "\n",
    "Let's now investigate the second question we had."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How often are new questions repeats of older ones?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to investigate how often new questions are repeats of older ones. But we can't completely answer this, because we only have about 10% of the full Jeopardy question dataset. We can still can investigate it at least.\n",
    "\n",
    "To try tackling that question, we can:\n",
    "* Sort `jeopardy` in order of ascending air date.\n",
    "* Maintain a set called `terms_used` that will be empty initially.\n",
    "* Iterate through each row of `jeopardy`.\n",
    "* Split `clean_question` into words, remove any word shorter than 6 characters, and check if each word occurs in `terms_used`.\n",
    "    * If it does, increment a counter.\n",
    "    * Add each word to `terms_used`.\n",
    "\n",
    "This will enable us to check if the terms in questions have been used previously or not. Only looking at words with six or more characters enables us to filter out words like `the` and `than`, which are commonly used, but don't tell us a lot about a question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6894031359073245\n"
     ]
    }
   ],
   "source": [
    "question_overlap = []\n",
    "terms_used = set()\n",
    "\n",
    "jeopardy = jeopardy.sort_values(\"Air Date\")\n",
    "\n",
    "for index, row in jeopardy.iterrows():\n",
    "    split_question = row[\"clean_question\"].split(\" \")\n",
    "    split_question = [word for word in split_question if len(word) > 5]\n",
    "    \n",
    "    match_count = 0\n",
    "    \n",
    "    for word in split_question:\n",
    "        if word in terms_used:\n",
    "            match_count += 1\n",
    "        terms_used.add(word)        \n",
    "    if len(split_question) > 0:\n",
    "            match_count /= len(split_question)\n",
    "            \n",
    "    question_overlap.append(match_count)\n",
    "\n",
    "jeopardy[\"question_overlap\"] = question_overlap\n",
    "print(jeopardy[\"question_overlap\"].mean())           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that, on average, about 70% of the terms in a new question already appeared in previous questions. \n",
    "\n",
    "This only looks at a small set of questions, and it doesn't look at phrases since it looks at single terms. This makes it relatively insignificant, but it does mean that it's worth looking more into the recycling of questions.\n",
    "\n",
    "In the next section, we try to figure out a way to identify the high value questions to focus on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the most promising topics to focus on?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we look at previous Jeopardy questions, it would be smart to focus on high value questions/topics that will help us earn more money.\n",
    "\n",
    "We can actually figure out which terms correspond to high-value questions by using a chi-squared test to prove any statistical significance. We'll first need to narrow down the questions into two categories:\n",
    "* Low value - Any row where `value` is less than `800`\n",
    "* High value - Any row where `value` is more than `800`\n",
    "\n",
    "We'll then be able to loop through each of the terms from `terms_used` and:\n",
    "* Find the number of low value questions the word occurs in.\n",
    "* Find the number of high value questions the word occurs in.\n",
    "* Find the percentage of questions the word occurs in.\n",
    "* Based on the percentage of questions the word occurs in, find the expected counts.\n",
    "* Compute the chi squared value based on the expected and observed counts for high and low value questions.\n",
    "\n",
    "We can then find the words with the biggest differences in usage between high and low value questions, by selecting the words with the highest associated chi-squared values. Doing this for all the words would take a very long time, so we'll just do it for a small sample now.\n",
    "\n",
    "We sart by creating a function that categorizes questions based on the value criteria we previously introduced (more or less than $800)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def categorize_value(row):\n",
    "    if row[\"clean_value\"] > 800:\n",
    "        value = 1\n",
    "    else:\n",
    "        value = 0\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then apply this function to each row in `jeopardy` and return the result in a new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jeopardy[\"high_value\"] = jeopardy.apply(categorize_value, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create another function that calculates and returns the number of times a word is counted in both high value and low value questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_high_low(word):\n",
    "    low_count = 0\n",
    "    high_count = 0\n",
    "    for index, row in jeopardy.iterrows():\n",
    "        clean_question = row[\"clean_question\"].split(\" \")\n",
    "        if word in clean_question:\n",
    "            if row[\"high_value\"] == 1:\n",
    "                high_count += 1\n",
    "            else:\n",
    "                low_count += 1\n",
    "    return high_count, low_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test this function, we randomly pick ten elements of `terms_used` and append them to a list called `comparison_terms`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['politicalsounding', 'xlibris', 'hrefhttpwwwjarchivecommedia20100706dj28jpg', 'plenty', 'eddies', 'committees', 'nephrite', 'lesley', 'dynamite', 'formeda']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "comparison_terms = random.sample(terms_used, 10)\n",
    "print(comparison_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then iterate through those terms and run the `count_high_low` function for each of them. The returned `high_count` and `low_count` values will be appended to a list called `observed_expected`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "observed_expected = []\n",
    "\n",
    "for term in comparison_terms:\n",
    "    observed_expected.append(count_high_low(term))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the `observed_expected` list!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 0), (1, 0), (1, 6), (1, 0), (1, 0), (1, 0), (1, 1), (0, 3), (1, 0)]\n"
     ]
    }
   ],
   "source": [
    "print(observed_expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that among the 10 words randomly picked from `terms_used`, some appeared more than once in high or low value questions.\n",
    "\n",
    "Now that we've found the observed counts for a few terms, we can compute their expected count and associated chi-squared value, to prove any statistically significant difference in usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import chisquare\n",
    "\n",
    "high_value_count = jeopardy[jeopardy[\"high_value\"] == 1].shape[0]\n",
    "low_value_count = jeopardy[jeopardy[\"high_value\"] == 0].shape[0]\n",
    "\n",
    "chi_squared = []\n",
    "\n",
    "for element in observed_expected:\n",
    "    total = sum(element)\n",
    "    total_prop = total / len(jeopardy)\n",
    "    expected_high_count = total_prop * high_value_count\n",
    "    expected_low_count = total_prop * low_value_count\n",
    "    \n",
    "    observed = np.array([element[0], element[1]])\n",
    "    expected = np.array([expected_high_count, expected_low_count])\n",
    "    chi_squared.append(chisquare(observed, expected))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469),\n",
       " Power_divergenceResult(statistic=2.487792117195675, pvalue=0.11473257634454047),\n",
       " Power_divergenceResult(statistic=2.487792117195675, pvalue=0.11473257634454047),\n",
       " Power_divergenceResult(statistic=0.7083506539662141, pvalue=0.39999189913636146),\n",
       " Power_divergenceResult(statistic=2.487792117195675, pvalue=0.11473257634454047),\n",
       " Power_divergenceResult(statistic=2.487792117195675, pvalue=0.11473257634454047),\n",
       " Power_divergenceResult(statistic=2.487792117195675, pvalue=0.11473257634454047),\n",
       " Power_divergenceResult(statistic=0.4448774816612795, pvalue=0.5047776487545996),\n",
       " Power_divergenceResult(statistic=1.205888538380652, pvalue=0.27214791766902047),\n",
       " Power_divergenceResult(statistic=2.487792117195675, pvalue=0.11473257634454047)]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the terms had a significant difference in usage between high value and low value questions. Additionally, the frequencies were too small, so the chi-squared test isn't as valid. It would be better to run this test with only terms that have higher frequencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we analyzed a dataset of questions previously asked in the game Jeopardy to try and figure out some patterns that could help us win in future games.\n",
    "\n",
    "We observed that most questions or topics repeat in the game and that it would be a good strategy to focus on repeating topics. More than that, we studied the link between words and the gain value of the questions they appeared in.\n",
    "\n",
    "Finally, we used our knowledge in significance testing to verify if a particular term has a statistically significant difference in usage between high value and low value questions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
